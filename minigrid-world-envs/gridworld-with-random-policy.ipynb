{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba0d927",
   "metadata": {},
   "source": [
    "### Step 1 - Prepare all the imports we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4628ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from base64 import b64encode\n",
    "\n",
    "import glob\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from gym.wrappers.record_video import RecordVideo\n",
    "from gym_minigrid.wrappers import *\n",
    "from gym import spaces\n",
    "from gym_minigrid.minigrid import OBJECT_TO_IDX, COLOR_TO_IDX\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcef575",
   "metadata": {},
   "source": [
    "### Step 2 - Create your first Grid World Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01bdd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MiniGrid-Empty-5x5-v0', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52986ab",
   "metadata": {},
   "source": [
    "### Step 3 - Interact with the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4f514a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0\n",
      "Observation: {'image': array([[[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [1, 0, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [1, 0, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [1, 0, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]]], dtype=uint8), 'direction': 3, 'mission': 'get to the green goal square'}\n",
      "Reward: 0\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "Info: {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info  = env.step(action)\n",
    "\n",
    "print(\"Action:\", action)\n",
    "print(\"Observation:\", obs)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"Truncated:\", truncated)\n",
    "print(\"Info:\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23801315",
   "metadata": {},
   "source": [
    "### Step 4 - Let's get a glimpse of this World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee0ae79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAB+CAYAAACHx8KbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADt0lEQVR4nO3dPW5bRxiG0U+Bl5A9xBVXkJqVgWgRZMkumwiQiinN7IFBOtZeAatkBy6SNTCFpAiwL4X8cN6Zkc8BBBUXGA00nx5SFKF7d7lcCoCMr3pvAOBLIroAQaILECS6AEGiCxAkugBBb166uN1um7yfbLVatViWT5zP595b+FfMxbPZzq6lGedit9vdXbvmmS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgS9eAv2lk6nU68v/Z+s1+sme16v1zdfM+FwONx8zf1+P+VczKbF2VVVbTab6eaix/l5pgsQJLoAQaILENQ9ur8+fnzXeyMMxVyw5DXMRffoPtnUwzfzm94bYSjmgiUzz0W3dy9c8+Pj5z+q6kNV/dxxL4zDXLBkxrkYLrpPvq6q+8fPx6r6vedmGIa5YMlMczFsdJ98+/jx5FhzPJrRlrlgyQxzMXx0P3VfVW/r4VeJX/puhYHcl7ngc/c13lxMF92qh2/i23r+VeLPrrthFOaCJaPNxZTR/a3GeuRiDOaCJaPNxXTRPdZ4r9HQ37HMBZ871nhzMXx0P9T4f40kz1ywZIa5GDa6M73vjhxzwZKZ5mK46H5fYz9K0Ye5YMmMczFMdA81zgvdjMNcsGTmuege3RlegyHPXLDkNcxF9+j+0HsDDMlcsOQ1zMUw/2UM4EsgugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxB0d7lcrl7cbrfXL/4Pq9WqxbJNnXanJuuuf1o3Wbeq6nw+N1u7hZZzMdv5zXZ2LX18/7HZ2q3Ob7fb3V279qbJV/wHTqc2PwTN7HpvYCyHw+Hma+73+3Zz4fz+1uLsqqo2m02Ttd+9f3fzNXvy8gJAkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJBbsL9is93G21w8m+3sWppxLl66BbtnugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQS/eDRiA2/JMFyBIdAGCRBcgSHQBgkQXIEh0AYL+AoYXqlThAEHLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "before_img = env.render()\n",
    "plt.imshow(before_img);\n",
    "\n",
    "action = env.actions.forward\n",
    "obs, reward, terminated, truncated, info  = env.step(action)\n",
    "\n",
    "after_img = env.render()\n",
    "\n",
    "action = env.actions.forward\n",
    "obs, reward, terminated, truncated, info  = env.step(action)\n",
    "\n",
    "final_img = env.render()\n",
    "\n",
    "plt.imshow(np.concatenate([before_img, after_img, final_img], 1));\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a68277",
   "metadata": {},
   "source": [
    "### Step 5 - Redefine the observations to get one-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "585010c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatObsWrapper(gym.core.ObservationWrapper):\n",
    "    def __init__(self, env, max_env_steps=50):\n",
    "        super().__init__(env)        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=((self.env.width-2) * (self.env.height-2) * 3,),  # number of cells\n",
    "            dtype='uint8'\n",
    "        )\n",
    "        self.unwrapped.max_steps = max_env_steps\n",
    "\n",
    "    def observation(self, obs):\n",
    "        env = self.unwrapped\n",
    "        full_grid = env.grid.encode()\n",
    "        full_grid[env.agent_pos[0]][env.agent_pos[1]] = np.array([\n",
    "            OBJECT_TO_IDX['agent'],\n",
    "            COLOR_TO_IDX['red'],\n",
    "            env.agent_dir\n",
    "        ])\n",
    "        full_grid = full_grid[1:-1, 1:-1]\n",
    "        \n",
    "        flattened_grid = full_grid.ravel()\n",
    "        return flattened_grid\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        return self.unwrapped.render(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b71dd31",
   "metadata": {},
   "source": [
    "### Step 6 - Check you world again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67b1a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [10  0  1  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  8  1  0] , Observation Shape:  (108,)\n",
      "Reward: 0\n",
      "terminated: False\n",
      "truncated: False\n",
      "info {}\n",
      "Image shape: (256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAES0lEQVR4nO3dsVEcVxzA4YfHJTigClXgmMxdQA1uQY4JjyJQSiw3QGT1INVwTqQZ5AGEj2X391bfFzHcLm+T3+y7Ze7+Z8fjcQA9v2x9AcDjxAlR4oQocUKUOCHq1+devLq68igX3tjhcDh77PfunBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToh6dhzDu3fv1roOJnR/f7/1Jezas3Gu7e7ubpV1Li4uVltr7fXWXOv8/Hzc3Nysstbl5eVqa31bb2u2tRAlTohKbWv/688xxu+v/Bt/LHEhsIH0nfOvMcY/rzj/NefC1tJxjjHGx43Oha3l4/yw0bmwtXycY4xxu9I5UDJFnKdsT21pmd0UcX4aY7z/H8e//3oOzGyKOMcY4+8xxucXHPf567Ewu2niHONlW1XbWfZiqjhvFzoGZjBVnF9+8PrHFxwDs5gqzh+53foCYEHTxfnUh4Zuhie07Mt0cT71wMeDIPZmuji/jMe3r95rsjfTxTmGuyQ/hynj/DS+/ziYj4axR1PGOcb3d093UvYo/U0Iz/kwxvjtwc+wN9PGOYb/a7JvU8fpCS17Nu17Ttg7cULU2fF4fPLF6+vrp1/kp2ccwzIOh8PZY79Pvefc48iCtdczjmG59bZmWwtR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQos1I4mVkpyzAr5QGzUpZhVsrbsq2FKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKOMYOJlxDMswjuEB4xiWYRzD27KthShxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihCjjGDiZcQzLMI7hAeMYlmEcw9uyrYUocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQo4xg42ZrjGG4O633b+xhjXF6t943vxjE8YBzDMtYcxzAO6yxTYlsLUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKLNSONmas1L27KlZKe6cECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiHp2HAOwHXdOiBInRIkTosQJUeKEKHFC1L/5EtZqwo7K2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make use of the Flat Observable in your MiniGrid Environment\n",
    "env = FlatObsWrapper(gym.make('MiniGrid-Empty-8x8-v0', render_mode=\"rgb_array\"), max_env_steps = 200)\n",
    "\n",
    "# Reset the environment\n",
    "env.reset()\n",
    "\n",
    "# Select the action right\n",
    "action = env.actions.right\n",
    "\n",
    "# Take a step in the environment and store it in appropriate variables\n",
    "obs, reward, terminated, truncated, info  = env.step(action)\n",
    "\n",
    "\n",
    "# Render the current state of the environment\n",
    "img = env.render()\n",
    "print('Observation:', obs, ', Observation Shape: ', obs.shape)\n",
    "print('Reward:', reward)\n",
    "print('terminated:', terminated)\n",
    "print('truncated:', truncated)\n",
    "print('info', info)\n",
    "print('Image shape:', img.shape)\n",
    "plt.imshow(img);\n",
    "plt.axis('off')  # Hide axes for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71e647",
   "metadata": {},
   "source": [
    "### Step 7 - Define a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2533fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random policy - nothing special\n",
    "class RandPolicy:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "        \n",
    "    def act(self, *unused_args):\n",
    "        return self.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790dcae",
   "metadata": {},
   "source": [
    "### Step 8 - Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0572cfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 0\n",
      "Total length: 11\n",
      "Reward: 0\n",
      "Terminated: False\n",
      "Truncated: True\n",
      "Info {}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEG0lEQVR4nO3dQU4bWRRA0U/UO0gG7IDeQ3rMrBVvoSWzm54xNCthGWzIPWgiOchlO8SuusHnSAhUBr3P4KrKVqn+zXa7HUDPp6UXAOwnTogSJ0SJE6LECVF/HHrx8fHRR7kkvLy8LL2Ei9lsNjf7jjtzQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcEHVwr5S5PT8/zzLn/v5+tllzz/uos25vb8fT09Mss8YYY71ezzZrijMnRIkTosR5os+vXzCX1HvOsn9fv/+z6Cq4Js6cJ/g2xvjy+vVt4bVwPcR5gr8mfoZLEucJ/nzz891SC+GqiPMdnD2ZgziP2PceczVxHM5JnEesfvI4nIs4D7gb/39Cu8/UcTgXcR6wWnoBXDVxTvg8jn/w444hLkmcE1Zn+h14L3Hu8XWcHufXi66EaybOPVYX+l34GeJ84278eEfQMe4Y4lLE+cZ77v5xxxCXIM43VjP9DRwjzh2/ckue2/k4N3Hu+JVHOq2H956clzjPaLX0AvhQPKZkx99LLwB2OHNClDgh6ma73U6++PDwMP0icBabzeZm3/HUe865Hre/Xq9nf7T/R/zfPuqs7/OW5rIWosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUfZKgYXZK2WHvVLMOmXe0lzWQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpTtGGBhtmPYYTsGs06ZtzSXtRAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBBlOwZYmO0YdtiOwaxT5i3NZS1EiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidE2Y6B38LTZr6nvY8xxvphvie+245hh+0Yfr9ZYzPPmBKXtRAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToiyVwosbGqvFGdOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRB3cjgFYjjMnRIkTosQJUeKEKHFClDgh6j+5ya9v6Iw4BgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function renders images of rollout of a given policy and environment\n",
    "def log_policy_rollout(policy, env):\n",
    "    # Create environment with flat observation\n",
    "    obs, reward, terminated, truncated, info = [], -1, False, False, {}\n",
    "    \n",
    "    # Initialize environment\n",
    "    observation = env.reset()\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "    \n",
    "    truncated = False\n",
    "    while not truncated:\n",
    "        # Take a step\n",
    "        action = policy.act(observation)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        episode_length += 1\n",
    "        \n",
    "        print('Reward:', reward)\n",
    "        print('Terminated:', terminated)\n",
    "        print('Truncated:', truncated)\n",
    "        print('Info', info)\n",
    "        print('Step Nr.: ', episode_length)\n",
    "        if episode_length > 10:\n",
    "            truncated = True\n",
    "        # Display what you see\n",
    "        plt.imshow(env.render());\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        plt.pause(1)  # Pause for 1 second\n",
    "        clear_output(wait=True) \n",
    "        \n",
    "    print('Total reward:', episode_reward)\n",
    "    print('Total length:', episode_length)\n",
    "\n",
    "    env.close()\n",
    "    return obs, reward, terminated, truncated, info\n",
    "    \n",
    "# Test that the logging function is working\n",
    "test_env_name = 'MiniGrid-Empty-8x8-v0'\n",
    "env = FlatObsWrapper(gym.make('MiniGrid-Empty-8x8-v0', render_mode=\"rgb_array\"), max_env_steps = 200)\n",
    "rand_policy = RandPolicy(env.action_space)\n",
    "\n",
    "obs, reward, terminated, truncated, info = log_policy_rollout(rand_policy, env)\n",
    "print('Reward:', reward)\n",
    "print('Terminated:', terminated)\n",
    "print('Truncated:', truncated)\n",
    "print('Info', info)\n",
    "\n",
    "plt.imshow(env.render());\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d18191",
   "metadata": {},
   "source": [
    "### Step 9 - Improve what you see, add a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a5f1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, './video',\n",
    "                      episode_trigger = lambda episode_number: True, \n",
    "                      video_length=0, \n",
    "                      name_prefix=\"full_episode\")\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name,render_mode=\"rgb_array\"), max_env_steps=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed21ea",
   "metadata": {},
   "source": [
    "### Step 11 - Prove it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a57de20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gym/wrappers/record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/victor/Documents/python-projects/medium-py/minigrid-world-envs/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/victor/Documents/python-projects/medium-py/minigrid-world-envs/video/full_episode-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/victor/Documents/python-projects/medium-py/minigrid-world-envs/video/full_episode-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/victor/Documents/python-projects/medium-py/minigrid-world-envs/video/full_episode-episode-0.mp4\n",
      "Total reward: 0.946\n",
      "Total length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" autoplay \n",
       "                loop controls style=\"height: 400px;\">\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.946\n",
      "Terminated: True\n",
      "Truncated: False\n",
      "Info {}\n"
     ]
    }
   ],
   "source": [
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "# Plots videos of rollouts (episodes) of your random policy and environment\n",
    "def log_policy_rollout(policy, env_name):\n",
    "    # Create environment with flat observation\n",
    "    env = gen_wrapped_env(env_name)\n",
    "    obs, reward, terminated, truncated, info = [], -1, False, False, {}\n",
    "    \n",
    "    # Initialize environment\n",
    "    observation = env.reset()\n",
    "    actions = [2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2]\n",
    "    terminated = False\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "\n",
    "    for i in range(len(actions)):\n",
    "    \n",
    "        # Take a step\n",
    "        action = policy.act(observation)\n",
    "        # obs, reward, terminated, truncated, info = env.step(action)\n",
    "        obs, reward, terminated, truncated, info = env.step(actions[i])\n",
    "        episode_reward += reward\n",
    "        episode_length += 1\n",
    "        if i == len(actions):\n",
    "             show_video()\n",
    "             return obs, reward, terminated, truncated, info\n",
    "            \n",
    "\n",
    "    print('Total reward:', episode_reward)\n",
    "    print('Total length:', episode_length)\n",
    "\n",
    "    env.close()\n",
    "    show_video()\n",
    "    return obs, reward, terminated, truncated, info\n",
    "    \n",
    "# Test the logging function\n",
    "test_env_name = 'MiniGrid-Empty-8x8-v0'\n",
    "rand_policy = RandPolicy(FlatObsWrapper(gym.make(test_env_name)).action_space)\n",
    "\n",
    "obs, reward, terminated, truncated, info = log_policy_rollout(rand_policy, test_env_name)\n",
    "print('Reward:', reward)\n",
    "print('Terminated:', terminated)\n",
    "print('Truncated:', truncated)\n",
    "print('Info', info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
