{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4628ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gym/envs/registration.py:307: DeprecationWarning: The package name gym_minigrid has been deprecated in favor of minigrid. Please uninstall gym_minigrid and install minigrid with `pip install minigrid`. Future releases will be maintained under the new package name minigrid.\n",
      "  fn()\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from base64 import b64encode\n",
    "\n",
    "import glob\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from gym.wrappers.record_video import RecordVideo\n",
    "from gym_minigrid.wrappers import *\n",
    "from gym import spaces\n",
    "from gym_minigrid.minigrid import OBJECT_TO_IDX, COLOR_TO_IDX\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee0ae79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 5\n",
      "Observation: {'image': array([[[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [8, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0]],\n",
      "\n",
      "       [[2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [2, 5, 0]]], dtype=uint8), 'direction': 0, 'mission': 'get to the green goal square'}\n",
      "Reward: 0\n",
      "Terminated: False\n",
      "truncated: False\n",
      "Info: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAC1CAYAAAD86CzsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEgElEQVR4nO3csY3jVhSG0StjStgevJEqcMxYRVghY7sFx25gS5BTxnYDitY9rGugA0keYSF5FP3vkTwHEHYBBrqYufjA0ePMbp7nAiDjh9YDAGyJ6AIEiS5AkOgCBIkuQNDb/108Ho/NH23Y7/etR6BD5/O59QhVZT95bBzH3bNr7nQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyDorfUAr5qmqen7D8PQxQxVfXwteNfL96OHOXqYoXfudAGCRBcgSHQBgkQXIGiR0f2lqn5sPQQ8YDf5yGKeXrj30/X1tar+rKo/2o4D/7GbfGSR0b35fH39XFWnuiz53y0HgqtHu1llP1l4dO8drq+vdVnyvxrOAvcO11eV/WRF0b35XFW/VtW3utxdnKrqn5YDwR37ySIP0l7xqS53F1/K4Qb9sZ/btbo73Uduhxvf6v3zNXcX9MJ+bssmonvzqS4HG7fDjSqHb/Tj+/20m+u0qejeO9z96/EeenMou7lWm43uvdvjPYdyuEFf7Ob6rPYgDaBH7nTLj3D0y26uz2aje7r+67CCHp3Kbq6VjxcAgjZ1p+s5SHpmP7dhE9G9nfr6UY0e2c9tWW10/W47PbOf27W66PorTvTMfrKa6J7KaS99OpW/p8u7RUfXM4z0ym7yzCKj6+CBXtlNPrLI6P7WegB4wm7yEb8cARAkugBBogsQJLoAQaILELSb5/npxePx+PxiyH6/bz0CHTqfz61HqCr7yWPjOO6eXVvMI2PTNDV9/2EYupihqo+vBe96+X70MEcPM/TOxwsAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILEPTWeoBXDcPQeoTmM0zjdPnP2HSMqt8bv39nWu/FTes5pnGymy9YTHSnaWr6/sMwNJ+h+ULzUOu9uMW29Rz28zU+XgAIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUI2s3z/PTi8Xh8fjFkv9+3HoEOnc/n1iNUlf3ksXEcd8+uudMFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQjazfPcegaAzXCnCxAkugBBogsQJLoAQaILECS6AEH/Ag6vwL1CcKl+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('MiniGrid-Empty-5x5-v0', render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "before_img = env.render()\n",
    "plt.imshow(before_img);\n",
    "action = env.actions.forward\n",
    "action = env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info  = env.step(action)\n",
    "\n",
    "# Print information about the step\n",
    "print(\"Action:\", action)\n",
    "print(\"Observation:\", obs)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"truncated:\", truncated)\n",
    "print(\"Info:\", info)\n",
    "# Render the environment on the screen\n",
    "# Note: This method may not work in a headless environment or Jupyter notebook without additional setup\n",
    "after_img = env.render()\n",
    "\n",
    "plt.imshow(np.concatenate([before_img, after_img], 1));\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bacbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585010c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatObsWrapper(gym.core.ObservationWrapper):\n",
    "    \"\"\"Fully observable gridworld returning a flat grid encoding.\"\"\"\n",
    "\n",
    "    def __init__(self, env, max_env_steps=50):\n",
    "        super().__init__(env)\n",
    "\n",
    "        # Since the outer walls are always present, we remove left, right, top, bottom walls\n",
    "        # from the observation space of the agent. There are 3 channels, but for simplicity\n",
    "        # in this assignment, we will deal with flattened version of state.\n",
    "        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=((self.env.width-2) * (self.env.height-2) * 3,),  # number of cells\n",
    "            dtype='uint8'\n",
    "        )\n",
    "#         self.unwrapped.max_steps = max_env_steps\n",
    "\n",
    "    def observation(self, obs):\n",
    "        # this method is called in the step() function to get the observation\n",
    "        # we provide code that gets the grid state and places the agent in it\n",
    "        env = self.unwrapped\n",
    "        full_grid = env.grid.encode()\n",
    "        full_grid[env.agent_pos[0]][env.agent_pos[1]] = np.array([\n",
    "            OBJECT_TO_IDX['agent'],\n",
    "            COLOR_TO_IDX['red'],\n",
    "            env.agent_dir\n",
    "        ])\n",
    "        full_grid = full_grid[1:-1, 1:-1]   # remove outer walls of the environment (for efficiency)\n",
    "        \n",
    "        flattened_grid = full_grid.ravel()\n",
    "        return flattened_grid\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        \"\"\"This removes the default visualization of the partially observable field of view.\"\"\"\n",
    "        return self.unwrapped.render(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b1a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [10  0  1  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  8  1  0] , Observation Shape:  (108,)\n",
      "Reward: 0\n",
      "terminated: False\n",
      "truncated: False\n",
      "info {}\n",
      "Image shape: (256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAES0lEQVR4nO3dsVEcVxzA4YfHJTigClXgmMxdQA1uQY4JjyJQSiw3QGT1INVwTqQZ5AGEj2X391bfFzHcLm+T3+y7Ze7+Z8fjcQA9v2x9AcDjxAlR4oQocUKUOCHq1+devLq68igX3tjhcDh77PfunBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToh6dhzDu3fv1roOJnR/f7/1Jezas3Gu7e7ubpV1Li4uVltr7fXWXOv8/Hzc3Nysstbl5eVqa31bb2u2tRAlTohKbWv/688xxu+v/Bt/LHEhsIH0nfOvMcY/rzj/NefC1tJxjjHGx43Oha3l4/yw0bmwtXycY4xxu9I5UDJFnKdsT21pmd0UcX4aY7z/H8e//3oOzGyKOMcY4+8xxucXHPf567Ewu2niHONlW1XbWfZiqjhvFzoGZjBVnF9+8PrHFxwDs5gqzh+53foCYEHTxfnUh4Zuhie07Mt0cT71wMeDIPZmuji/jMe3r95rsjfTxTmGuyQ/hynj/DS+/ziYj4axR1PGOcb3d093UvYo/U0Iz/kwxvjtwc+wN9PGOYb/a7JvU8fpCS17Nu17Ttg7cULU2fF4fPLF6+vrp1/kp2ccwzIOh8PZY79Pvefc48iCtdczjmG59bZmWwtR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQos1I4mVkpyzAr5QGzUpZhVsrbsq2FKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKOMYOJlxDMswjuEB4xiWYRzD27KthShxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihCjjGDiZcQzLMI7hAeMYlmEcw9uyrYUocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQo4xg42ZrjGG4O633b+xhjXF6t943vxjE8YBzDMtYcxzAO6yxTYlsLUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKLNSONmas1L27KlZKe6cECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiHp2HAOwHXdOiBInRIkTosQJUeKEKHFC1L/5EtZqwo7K2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert MiniGrid Environment with Flat Observable\n",
    "env = FlatObsWrapper(gym.make('MiniGrid-Empty-8x8-v0', render_mode=\"rgb_array\"), max_env_steps = 200)\n",
    "\n",
    "# Reset the environment\n",
    "env.reset()\n",
    "\n",
    "# Select the action right\n",
    "action = env.actions.right\n",
    "\n",
    "# Take a step in the environment and store it in appropriate variables\n",
    "obs, reward, terminated, truncated, info  = env.step(action)\n",
    "\n",
    "\n",
    "# Render the current state of the environment\n",
    "img = env.render()\n",
    "################# YOUR CODE ENDS HERE ###############################\n",
    "\n",
    "print('Observation:', obs, ', Observation Shape: ', obs.shape)\n",
    "print('Reward:', reward)\n",
    "print('terminated:', terminated)\n",
    "print('truncated:', truncated)\n",
    "print('info', info)\n",
    "print('Image shape:', img.shape)\n",
    "plt.imshow(img);\n",
    "plt.axis('off')  # Hide axes for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5f1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    # env = RecordVideo(env, './video',  episode_trigger = lambda episode_number: True)\n",
    "    # env = RecordVideo(env, './video', video_length=500, name_prefix=\"snippet\")\n",
    "    env = RecordVideo(env, './video', episode_trigger = lambda episode_number: True, video_length=0, name_prefix=\"full_episode\")\n",
    "    return env\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name,render_mode=\"rgb_array\"), max_env_steps=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2533fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random agent - we only use it in this cell for demonstration\n",
    "class RandPolicy:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "        \n",
    "    def act(self, *unused_args):\n",
    "        return self.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a57de20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Moviepy - Building video /Users/victor/Documents/python-projects/medium-py/minigrid-world-envs/video/full_episode-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/victor/Documents/python-projects/medium-py/minigrid-world-envs/video/full_episode-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/victor/Documents/python-projects/medium-py/minigrid-world-envs/video/full_episode-episode-0.mp4\n",
      "11\n",
      "Total reward: 0.9578125\n",
      "Total length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" autoplay \n",
       "                loop controls style=\"height: 400px;\">\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0 10  0  0] 0.9578125 True False {}\n"
     ]
    }
   ],
   "source": [
    "# This function plots videos of rollouts (episodes) of a given policy and environment\n",
    "def log_policy_rollout(policy, env_name):\n",
    "    # Create environment with flat observation\n",
    "    env = gen_wrapped_env(env_name)\n",
    "    obs, reward, terminated, truncated, info = [], -1, False, False, {}\n",
    "    # Initialize environment\n",
    "    observation = env.reset()\n",
    "    actions = [2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2]\n",
    "    terminated = False\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "#     i = 0\n",
    "    # Run until done == True\n",
    "#     while not terminated:\n",
    "    for i in range(len(actions)):\n",
    "    \n",
    "        # Take a step\n",
    "        action = policy.act(observation)\n",
    "        # obs, reward, terminated, truncated, info = env.step(action)\n",
    "        obs, reward, terminated, truncated, info = env.step(actions[i])\n",
    "        print(i)\n",
    "        episode_reward += reward\n",
    "        episode_length += 1\n",
    "        if i == len(actions):\n",
    "             show_video()\n",
    "             return obs, reward, terminated, truncated, info\n",
    "            \n",
    "\n",
    "    print('Total reward:', episode_reward)\n",
    "    print('Total length:', episode_length)\n",
    "\n",
    "#     env.close()\n",
    "    show_video()\n",
    "    return obs, reward, terminated, truncated, info\n",
    "    \n",
    "# Test that the logging function is working\n",
    "test_env_name = 'MiniGrid-Empty-8x8-v0'\n",
    "rand_policy = RandPolicy(FlatObsWrapper(gym.make(test_env_name)).action_space)\n",
    "\n",
    "obs, reward, terminated, truncated, info = log_policy_rollout(rand_policy, test_env_name)\n",
    "print(obs, reward, terminated, truncated, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b85f4",
   "metadata": {},
   "source": [
    "https://minigrid.farama.org/environments/minigrid/BlockedUnlockPickupEnv/\n",
    "https://colab.research.google.com/github/goodboychan/chans_jupyter/blob/main/_notebooks/2020-08-06-03-Policy-Gradient-With-Gym-MiniGrid.ipynb#scrollTo=Nz2O5Rmr97z0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6137d26",
   "metadata": {},
   "source": [
    "        \"\"\"Run one timestep of the environment's dynamics using the agent actions.\n",
    "\n",
    "        When the end of an episode is reached (``terminated or truncated``), it is necessary to call :meth:`reset` to\n",
    "        reset this environment's state for the next episode.\n",
    "\n",
    "        .. versionchanged:: 0.26\n",
    "\n",
    "            The Step API was changed removing ``done`` in favor of ``terminated`` and ``truncated`` to make it clearer\n",
    "            to users when the environment had terminated or truncated which is critical for reinforcement learning\n",
    "            bootstrapping algorithms.\n",
    "\n",
    "        Args:\n",
    "            action (ActType): an action provided by the agent to update the environment state.\n",
    "\n",
    "        Returns:\n",
    "            observation (ObsType): An element of the environment's :attr:`observation_space` as the next observation due to the agent actions.\n",
    "                An example is a numpy array containing the positions and velocities of the pole in CartPole.\n",
    "            reward (SupportsFloat): The reward as a result of taking the action.\n",
    "            terminated (bool): Whether the agent reaches the terminal state (as defined under the MDP of the task)\n",
    "                which can be positive or negative. An example is reaching the goal state or moving into the lava from\n",
    "                the Sutton and Barton, Gridworld. If true, the user needs to call :meth:`reset`.\n",
    "            truncated (bool): Whether the truncation condition outside the scope of the MDP is satisfied.\n",
    "                Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds.\n",
    "                Can be used to end the episode prematurely before a terminal state is reached.\n",
    "                If true, the user needs to call :meth:`reset`.\n",
    "            info (dict): Contains auxiliary diagnostic information (helpful for debugging, learning, and logging).\n",
    "                This might, for instance, contain: metrics that describe the agent's performance state, variables that are\n",
    "                hidden from observations, or individual reward terms that are combined to produce the total reward.\n",
    "                In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination,\n",
    "                however this is deprecated in favour of returning terminated and truncated variables.\n",
    "            done (bool): (Deprecated) A boolean value for if the episode has ended, in which case further :meth:`step` calls will\n",
    "                return undefined results. This was removed in OpenAI Gym v26 in favor of terminated and truncated attributes.\n",
    "                A done signal may be emitted for different reasons: Maybe the task underlying the environment was solved successfully,\n",
    "                a certain timelimit was exceeded, or the physics simulation has entered an invalid state.\n",
    "        \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
